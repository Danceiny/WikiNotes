## 2019-04-02

DONE

- 检查了优卡渠道抓取数据量未达到预期的问题，发现主要原因是优卡的API偶尔无法响应（根本原因是优卡这个网站质量较差，虽然没有反爬，但是前后端的性能都很差）。破解路径：尝试降低爬虫的并发度、增加下载延迟时间，争取两天内慢慢地爬取完业务方所需要的全部数据。
- [x] 熟悉了scrapy的signal模块及有关设置项。
- [x] 完成Q1的OKR review。
- [x] 熟悉pug模板中css样式的写法。

TODO

- 【紧急程度：100】抖音蓝V认证落地页的开发
- 可以用scrapy的signal机制，解决目前爬虫系统中状态追踪部分缺失的关键问题。关键步骤如下：定义一个全局异常处理类，注册事件通知回调，在各个回调中根据异常情况更新线索状态，并通过接口调用通知到爬虫系统的管理后台。(注：目前已完成demo，管理后台方面也已经开发了后端接口)

THREAT

- 由于不熟悉前端布局，特别是前端样式在各端的适配问题，抖音落地页的开发进度可能存在delay风险。
- 优卡渠道的数据问题，有可能pending在优卡渠道本身响应慢、无法响应，且由于降低爬取速度后调试周期变长，解决该问题的周期可能较长，且我个人对解决该问题及其在业务上产生收益的ROI存疑。
- python爬虫引入管理后台的API调用之后，存在耦合趋势。可以考虑**首先**将python爬虫去db化，所有db操作封装到管理后台的API。

THINKING

- scrapy的signal机制，给开发框架提供了一些思路。
- 今天OKR的review质量很高，引发了自我的思考。主要总结如下：
  - 需要提高模块级别的协作意识和质量
  - 定目标 有结果
  - 在开发业务驱动的（爬虫）系统时，也要自顶向下地思考解决方案
  - 即便业务上没有数据管理的需求，但是仍然需要做好数据管理，这是成果数据化的前提
  - 组内需要提前沟通设计方案，后动手实现
  - 即便很紧急、时间不够，不管以任何形式、任何程度，也还是要做可行性验证 

- 学习了CAS/Raft协议，感觉之前没有深入了解实在是太可惜、太不应该了，为了更加深入地理解、应用，打算到爬虫系统当中找一个切入的点，做一个实际可用的小demo。



## 2019-04-03

DONE

- 抖音落地页的web版开发，基本上已经成型

TODO

- 抖音落地页的wap版开发
- 调试抖音落地页的样式兼容性(web+chrome, wap+微信内置浏览器)

THREAT

- 抖音落地页今天的开发进度"符合预期"，挺慢的，样式兼容性那块儿有点头大。

THINKING

- 落地页的开发主要补充了两个知识点：一个是flex布局；另一个就是利用纯css画一些简单图形。但是令人气馁的是一些简单的样式居中还是没处理好，虽然以前有看过css布局这一块，但实际搞起来就是令人难以分析的"层叠样式"了。这一块的知识缺陷，希望有空能去系统地完整地学一学css再说吧。。。

- 由于设计稿中web和wap两个版本差异较大，因此应该是两个页面。加上有主站banner的跳转，涉及到一个UA的判断，需要细致思考一下这个跳转、加载的流程架构问题。

- sketch文档导出的html还原度很高，感觉自己的html+css水平无法实现如此高的还原度，因此想着可以走点捷径，于是倒腾了一下代码导出，结论是目前没有很好的**适用于二次开发**的设计稿转代码的工具：
  - sketch直接生成代码：
    - <https://github.com/MaxBazarov/exporter> 生成代码较简单，但是仍然无法二次开发
  - 一篇讲前端代码生成工具开发经验的博客：<https://www.cnblogs.com/sskyy/p/7813943.html>
  - 机器学习类（未尝试）：<https://github.com/tonybeltramelli/pix2code>





## 2019-04-04

DONE

- 抖音落地页的wap版开发基本完成
- 补一个昨天完成的：parser-engine修复了解析器中查找父节点的bug，版本号更新至v0.1.3。

THREAT

- 抖音落地页的样式兼容性问题需要继续完善；性能问题还需要评估

TODO

- 修复抖音落地页在微信内置浏览器、Safari浏览器、360安全浏览器、QQ浏览器等主流浏览器，以及各主流手机机型的内置浏览器等等环境下的样式兼容性问题。

THINKING

- sketch导出的html查看样式，选中时会带一些"选中样式"，copy到代码里来那就会有问题，这算是一个小巨坑吧……
- 开发落地页有pc和wap两个版本，涉及到两套css（这个还好解决）和两套图片（这个思来想去，除了听闻CDN可以自适应图片分配率以外，没有想到其他的**纯前端**解决方案），因此目前我的一个实现是，用后端渲染pug模板，后端判断UA，来选择不同的图片url，然后把图片url给前端渲染出来。希望尽快找专业前端交流一下这个问题。因为一开始写的纯html，然后要用pug，于是在网上找了个工具:<https://html2jade.org/>，挺好用的，但是意外发现pug不支持`()=>{}`这种写法。
  - 补充：用div标签的背景图代替img标签，从而用加载不同css的方法解决了多端图片适配的问题。



## 2019-04-08

DONE

TODO

THREAT

THINKING



- oppo r9 系统自带浏览器 UC浏览器
- iphone 6p Safari浏览器 QQ浏览器
- 红米note3 系统自带浏览器

## 2019-04-16

DONE
- 截至目前已经爬取了齐家网旺铺信息条数90000+，其中9600+有手机号
- parser_engine升级到v0.1.4，优化了`ItemClassloader`；spider_common发布v0.0.1，完成了clue模块的迁移和服务化。
- 优化了爬虫系统管理后台获取scrapyd信息的客户端调用。

TODO

- 齐家网爬虫部署上线，将数据灌到dw
- 着手抖音抓包数据在线编辑以及接入游龙系统的开发

THREAT
- 推进spider_common模块的上线，因为还没有解决在docker build时拉取gitlab代码仓库的问题，只能暂时先用github，存在一定隐患。此外，上线新的依赖，需要避免对线上已有爬虫造成不良影响。

THINKING
- 在爬虫系统管理后台的前端和后端、python爬虫与管理后台的后端，都涉及大量的API约定，尽管项目本身暂时没有太大难度，但是如何能高效且尽可能保证向前向后兼容地设计API，还是挺有挑战性的。



## 2019-04-17

DONE

- 齐家网旺铺信息累计爬取60万条（今天新增50万+），已向DW发送了约4万条数据。
- 抖音蓝V落地页所在的项目完成架构迁移：由express迁移至eggjs

TODO

- 使用vue重写har文件转换器（原因是原来的代码组织方式是不利于拓展后端功能）
- 继续爬取齐家网，保证向DW发送8000以上的手机号数据。

THREAT

- 春游组织要抓紧了
- 还得看看rpc

THINKING

- 昨天睡眠质量不佳，今天感觉状态不太好。早上碰到docker容器内部dns解析异常（相同的操作系统，同样的docker安装姿势，家里的台式机就没有毛病），折腾了一阵子没弄好，不过基本确定是docker网桥问题，走host网络可以勉强正常使用；下午打算在express项目上采用谢聪推荐的miniui.js来做在线表格编辑，折腾了一小时感觉一无所获，且无论是看源代码还是看UI，都挺不满意的（特别是miniui用了jquery，而我没用过jq……），于是转而想拥抱比较熟悉且轮子特别多的vue——于是乎又要在node的后端项目里融合前端vue，这里面必定是要踩坑的，想到之前爬虫的后台用eggjs已经做过前后端的融合架构，于是决定将express迁移到eggjs，免得日后维护两套框架的代码各种混乱。可是做express迁移的时候，因为既要前端渲染（之前已经做过了）又要后端渲染（抖音落地页就是后端渲染的，要维持），碰到一些前端的架构问题，导致有点心烦意乱。还好吃过加班餐之后给解决了，对现在的项目代码结构也有了更深入的认识。



## 2019-04-18

DONE

TODO

- 智慧营销：58listing
- 需求开放窗口期

THREAT

- 今天发现一神坑，就在8天以前twisted升级了一个版本，结果导致scrapyd挂了，扎心。而scrapyd项目已经很久没有更新，一堆bug没人清理，现在爬虫都靠scrapyd部署，有点忧伤。

THINKING



## 2019-04-19

DONE

- 抖音蓝V
  - 抓包流程优化：增加登录认证模块；完成游龙接口数据对接；优化了若干用户体验，比如可以显示用户的提交历史（基于浏览器本地缓存），解析超大抓包文件并显示（超过3万行表格数据），在线表格内容自动同步到本地缓存。
  - 培训了一位新兼职

TODO

- 抖音蓝V抓包流程优化：游龙接入的数据准确性检查（特别是涉及兼职人员工资结算的身份认证部分）；完成上线，投入使用。

THINKING

- 登录认证这块竟然花了不少时间，一开始想做得特别简单，后来想想这种线上系统，要是实在太简单的话，没有一点点安全性啊，相当于直接把游龙给暴露了，后来还是紧赶慢赶稍微强化了一下（虽然仍然没有用户表）。
- 从用户角度出发，本来想做不少事情的， 比如在编辑在线表格时能自动同步，显示每一次提交数据的历史记录等等，但是这个项目没有申请任何数据库资源，从ROI角度讲好像也没有太大必要，所以最后是采用客户端存储的方案做了一点努力，自己使用起来感觉还是挺舒适的。

- 昨天发现一神坑，就在8天以前twisted升级了一个版本，结果导致scrapyd挂了，扎心。而scrapyd项目已经很久没有更新，一堆bug没人清理，现在爬虫都靠scrapyd部署，有点忧伤。

本周内容（20190415 ～20190419）

1. 齐家网旺铺信息爬取：共计抓取旺铺数据约76万条，其中有效数据（带手机号）约8万条，先期交付DW约8000条有效数据，仍有约100万个库存种子（其中可能有重复）尚未爬取。
2. 抖音抓包流程优化：对douyin-support项目进行了重构，迁移至eggjs框架；引入在线表格组件，可以直接编辑经过解析的抓包文件；接入游龙系统，在线表格编辑完成后可一键提交至游龙。
3. 爬虫系统架构优化：parser_engine升级至v0.1.4；发布python爬虫公用代码库spider_common，初步完成了爬虫线索模块的服务化。