<http://ashma.info/web-backend-development-test/>

## 第一题

#### 背景分析
余额排行榜，需要实现以下功能：
1. 获取当前排行榜中的总地址（Address）数。
2. 分页获取当前排行榜数据（根据余额数倒序排序）。包含 Rank（名次）、Address（钱包地址）、Balance（余额）、 TxCount（参与事务的总数）。

#### 战略层
使用redis的zset有序列表来维护余额排行榜

#### 范围层
所需要用到的redis数据结构以及相应方法

#### 框架层
- 数据库：redis

redis中的zset有序集合数据结构支持根据浮点数分值进行倒排，且支持根据排序获取区间，符合背景分析的设计要求，因此优先考虑zset结构，而balance作为排序依据，显然应该是zset的score（或者构成score的重要组成部分）；
根据区块链等背景知识可以猜测，Address值是唯一的，也是我们关注的数据项之一，考虑到balance已经在score中，那么address应该在zset的member当中，另一个应该在member中的值是TxCount，但是考虑到member是一个string，如果需要存储两个数据，则涉及到编解码问题（如可以使用json），显然存在性能开销。另外，TxCount作为一个数值型数据，可能也会有排序需求，因此还是考虑将其放到score当中。如此，我们可以将balance和txcount组合成一个浮点数，其中整数部分是balance（根据题意balance是整型），浮点数部分是txcount，那么，
address为ppio1SDKRLjDALmN7kV874JLhZAv4Q9TKVhrhg的钱包地址，其数据结构如下：
```
member: "ppio1SDKRLjDALmN7kV874JLhZAv4Q9TKVhrhg"
score: 30000.2000
```
设zset的key为PPIO:Wallet，功能点实现如下：
1. 获取当前排行榜中的总地址（Address）数
```
zcard PPIO:Wallet
```

2. 分页获取当前排行榜数据
```
// start，end用于翻页
ZRANGE PPIO:Wallet start stop WITHSCORES
// 返回的member值，即为address
// 我们需要的rank值不会在redis返回结果中，可以通过start+index（元素在返回列表中的顺序索引）来计算得到
// 返回的score值，可以使用一些算法来进行整数部分和小数部分的拆分，但是需要注意浮点数精度的丢失问题
// 在Java中一个可能的方案就是使用BigDecimal类
```

#### 优缺点分析
优点：
- 支持balance+txcount的两重排序，如balance相同时的排序逻辑可以完美解决
- 无须序列化与反序列化

缺点：
- score值如果没处理好导致精度丢失，则会丢失txcount数据
- 如果有新的字段需要存储，则member的数据结构还是会变

## 第二题

#### 背景分析
下载文件的速度问题。
如果该文件的 HTTP 下载服务器对每个请求的下载限速为 10 KB/s，有什么办法让下载速度达到 100 KB/s？

#### 战略层
使用多线程分段并行下载加速

#### 范围层
设计分段下载以及合并的机制

#### 框架层
- 网络传输协议：https
- HTTP响应内容类型：二进制数据

首先明确一个问题，http状态码206通常代表断点续传，分段下载是通过服务端与客户端对http报文header的content-range这个头来进行约定的，形如`Range: bytes=start-end/total`，那么服务端与客户端各自要做的事情如下：
- 客户端发送请求，告诉服务端它需要下载0-end的数据（end通常是客户端选取的一个分块大小值，我假设为一个经验值，4MB）
- 服务端对文件比特流进行“定位”（即跳转到start的偏移地址），然后读取end-start字节的数据，发送给客户端（连同文件总大小）
- 客户端收到服务端的第一个响应，如果已经下载完成则结束（小文件就没必要分段了），如果没有下载完，客户端根据服务端告知的文件总大小，进行逻辑分段，开启多个线程各自请求一段，所有子线程结束后，主线程将各个比特流按照之前的逻辑分段顺序进行合并，写文件到本地，完成下载。

伪代码如下：
```
// client
req = Request()
req.headers['content-range'] = 'Range:bytes=0-4096'
response = do_http_request(req)
file_size = get_file_size(response.headers['content-range'])
threads_pool = new ThreadPool(size=file_size/4096)
streams = {0: response.stream}
index = 0
for i in range(4096, file_size, 4096):
	threads_pool[index++] = new Thread({
        req = Request()
        req.headers['content-range'] = 'Range:bytes=0-4096'
        response = do_http_request(req)
        streams.set(index, response.stream)
	})
threads_pool.run_all()
	
threads_pool.wait_all()
	
file = File()
for i in range(index):
	stream = streams[i]
	file.write(stream.read())
```
题中要求加速10倍，则通常开10个线程即可。


## 第三题
有点类似于supervisor，即要用shell来实现一个简单的supervisor
```
#!/bin/sh
while true;do
    ps -ef|grep ppio-demo |grep -v grep
    if [ $? -ne 0 ]
    then
    	/usr/local/bin/ppio-demo start
    	ps -ef | grep ppio-demo | grep -v grep | awk '{print $2}'
    else
    	echo "runing....."
    fi
done
```


## 第四题

user表
```
id int primary key
nickname varchar(64) unique 
follow_num int
follower_num int
weibo_num int


```
weibo表
```
id long primary key
content varchar(512)
post_time int
repost_time int
comment_num int
like_num int

author_nickname varchar(64)
```

1. `SELECT * FROM `weibo` WHERE author_nickname='xxxx';`

2. `SELECT sum(like_num) FROM weibo WHERE nickname='PPlabs2019';`

3. 
```
SELECT user.nickname, user.follow_num,user.follower_num, SUM(weibo.like_num) AS total_like_num FROM weibo 
LEFT JOIN weibo ON weibo.author_nickname=user.nickname 
GROUP BY user.nickname ORDER BY total_like_num DESC LIMIT 50
```

4. 索引
```
user:
	idx_nickname_follownum_followernum, // 联合索引，依次为nickname,follow_num, follower_num三列
	
weibo:
	idx_authornickname_likenum, // 联合索引，依次为author_nickname,like_num
```