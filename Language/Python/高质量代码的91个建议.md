1.  str.format
- `print '(greet) from (language).'.format(greet = "hello world",language = "python")`
- `"%(protocol)s://%(server)s:%(port)s/" % {"protocol": "http", "server": "example.co m", "port": 1080}`
![](http://opkk27k9n.bkt.clouddn.com/17-7-6/83131985.jpg)

2. 使用PEP8
pip install -U PEP8
pep8 --first optparse.py [--show-source]

3. 常量类
```python
class _const:
    class ConstError(TypeError):
        pass
    class ConstCaseError(ConstError):
pass
    def __setattr__(self, name, value):
        if self.__dict__.has_key(name):
            raise self.ConstError, "Can't change const.{}".format(name)
        if not name.isupper():
            raise self.ConstCaseError, "const name {} is not all uppercase".format
        self.__dict__[name] = value
import sys
sys.modules[__name__] = _const()
```

如果上面的代码对应的模块名为 const，使用时候只需要 import const，便可以直接定义 常量了，如以下代码:
```python
import const
const.COMPANY = "IBM"
```

无论采用哪一种方式来实现常量，都提倡将常量集中到一个文件中，因为这样有利于维 护，一旦需要修改常量的值，可以集中统一而不是逐个文件去检查。采用第二种方式实 现的常量可以这么做:将存放常量的文件命名为 constant.py ，并在其中定义一系列的 常量。

4. Pyhton字节码
可用dis模块分析。
```python
import dis
def swap1():
    x, y = 2, 3
    x, y = y, x
def swap2():
    x, y = 2, 3
    temp = x
    x=y
    y = temp
dis.dis(swap1)
dis.dis(swap2)
```


5. 生成器
```python
def fib():
    a, b = 0, 1
    while True:
        yield a
        a, b = b, a + b
from itertools import islice
# islice(iterator,stop)
print list(islice(fib(), 5))
```


6. type
```
class type(object)
 |  type(object_or_name, bases, dict)
 |  type(object) -> the object's type
 |  type(name, bases, dict) -> a new type
```

```python
def enum(*posarg, **keysarg):
	return type("Enum", (object,), dict(zip(posarg, range(len(posarg))), **keysarg))
Seasons = enum("Spring", "Summer", "Autumn", Winter=1)
```
**不建议使用type进行类型检查**!!!
isinstance()。

7. 枚举
```python
from flufl.enum import Enum
class Seasons(Enum): # 继承自 Enum 定义枚举
    Spring = "Spring"
    Summer = 2
    Autumn = 3
    Winter = 4
Seasons = Enum("Seasons", "Spring Sumter Autumn Winter")
```

flufl.enum 提供了 `__members__` 属性，可以对枚举名称进行迭代。
可以直接使用 value 属性获取枚举元素的值，比如:
`print Seasons.Summer.value`

flufl.enum 不支持枚举元素的比较。比如不支持 Seasons.Summer < Seasons.Autumn

Python3.4 中根据 PEP435 加入了枚举 Enum，其实现主要参考 flufl.enum ，但两者之间还 是存在一些差别，如 flufl.enum 允许枚举继承，而 Enum 仅在父类没有任何枚举成员的时 候才允许继承等。如果要在 Python3.4 之前的版本中使用枚举 Enum，可以安装 Enum 的向 后兼容包 enum34。

8. 警惕eval的安全漏洞
原型：`eval(expression[,globals[,locals]])`。

如果传入 globals 参数的字典中缺少 `__builtins__` 的时候，当前的全局命名空间将作为 globals 参数输入并且在表达式计算之前被解析。
预防：`eval(expression,{"__builtins__":None})`

在需要使用 eval 的地方可用安全性更好的 ast.literal_eval 替代。


9. 使用enumerate获取序列迭代的索引和值
不适用于字典。

10. 编码问题
![](http://opkk27k9n.bkt.clouddn.com/17-7-6/69280758.jpg)  


11. 使用with自动关闭资源
with语句的执行过程：

- 计算表达式的值，返回一个上下文管理器对象
- 加载上下文管理器对象的 `__exit__()` 方法以备后用
- 调用上下文管理器对象的 `__enter__()` 方法
- 如果 with 语句中设置了目标对象，则将 `__enter__()` 方法的返回值赋值给目标对象 执行 with 中的代码块
- 如果步骤 5 中代码正常结束，调用上下文管理其对象的 `__exit__()` 方法，其返回值直 接忽略
- 如果步骤 5 中代码执行过程中发生异常，调用上下文管理器对象的 `__exit__()` 方法， 并将异常类型、值及 traceback 信息作为参数传递给 `__exit__()` 方法。如果`__exit__()` 返回值为 false，则异常会被重新抛出;如果其返回值为 true，异常被挂 起，程序继续执行。

12. 自定义上下文管理器
```python
class MyContextManager(object):
def __enter__(self): # 实现 __enter__ 方法
        print "entering..."
    def __exit__(self, exception_type, exception_value, traceback):
        print "leaving"
        if exception_type is None:
            print "no exceptions!"
            return False
        elif exception_type is ValueError:
            print "value error!!!"
            return True
        else:
            print "other error"
            return True
with MyContextManager():
    print "Testing..."
    raise(ValueError) # 注释这一句会得到不同的效果
```

13. 使用else简化循环
![](http://opkk27k9n.bkt.clouddn.com/17-7-6/74245476.jpg)

14. 不要在finally中return

15. 字符串的基本用法
编写运行 Python2 上的程序，当需要判断变量是否为字符串时，应该使用 isinstance(s, basestring) ，这里的参数是 basestring 而不是 str 。因为 basestring 才是 str 和unicode 的基类，包含了普通字符串和 unicode 类型。

16. sort()  sorted()
```python
sorted(iterable[, cmp[, key[, reverse]]])
s.sort([cmp[, key[, reverse]]])
```
sorted() 函数会返回一个排序后的列表，原有列表 保持不变;而 sort() 函数会直接修改原有列表，函数返回为 None。

key 是一个带参数的函数，用来为每个元素提取比较值，默认为 None(即直接比较 每个元素).传入key比传入cmp效率要高。

![](http://opkk27k9n.bkt.clouddn.com/17-7-7/45355241.jpg)
```
from operator import itemgetter
class itemgetter(builtins.object)
 |  itemgetter(item, ...) --> itemgetter object
 |
 |  Return a callable object that fetches the given item(s) from its operand.
 |  After f = itemgetter(2), the call f(r) returns r[2].
 |  After g = itemgetter(2, 5, 3), the call g(r) returns (r[2], r[5], r[3])
```


17. 使用copy模块进行深拷贝
copy.deepcopy().

18. 深入掌握ConfigParser(配置文件)
- getboolean()的真值规则：0,no,false,off = False, 1,yes,true,on = True, else = ValueError
-
```conf
# format.conf
[DEFAULT]
conn_str = %(dbn)s://%(user)s:%(pw)s@%(host)s:%(port)s/%(db)s
dbn = mysql
user = root
host = localhost
port = 3306
[db1]
user = aaa
pw = ppp
db = example
[db2]
host = 192.168.0.110
pw = www
db = example
```
这是一个 SQLAlchemy 应用程序的配置文件，通过这个配置文件能够获取不同的数据库配置 相应的连接字符串，即 conn_str 。它通过不同的节名来获取格式化后的值时，根据不同配 置，得到不同的值:
```python
import ConfigParser
conf = ConfigParser.ConfigParser()
conf.read('format.conf')
print(conf.get('db1','conn_str'),conf.get('db2','conn_str'))
```

19. 使用 argparse 处理命令行参数
getopt 的问题在于两点:一个是长短配置项需要分开处理，二是对非法参数和必填参数的处 理需要手动。

```python
from optparse import OptionParser
parser = OptionParser()
parser.add_option("-f", "--file", dest="filename", help="write report to FILE", metava r="FILE")
parser.add_option("-q", "--quiet", action="store_false", dest="verbose", default=True,
 help="don't print status messages to stdout")
(options, args) = parser.parse_args()
```from optparse import OptionParser
parser = OptionParser()
parser.add_option("-f", "--file", dest="filename", help="write report to FILE", metava r="FILE")
parser.add_option("-q", "--quiet", action="store_false", dest="verbose", default=True,
 help="don't print status messages to stdout")
(options, args) = parser.parse_args()

#比optparse更好的argparse！！！！
import argparse
###
parser = argparse.ArgumentParser(prog="PROG")
subparsers = parser.add_subparsers(help="sub-command help")
parser_a = subparsers.add_parser("a", help="a help")
parser_a.add_argument("--bar", type=int, help="bar help")
parser.parse_args(["a", "--bar", "1"])
###
parser = argparse.ArgumentParser()
parser.add_argument("bar", type=argparse.FileType("w"))
parser.parse_args(["out.txt"])

### 虽然 argparse 已经非常好用，但又出现了 docopt ，它是比 argparse 更先进更 易用的命令行参数处理器.
```

20. 使用pandas处理大型CSV文件
Python模块csv提供了一系列与CSV处理相关的API。

21. xml解析，一般用ElementTree,性能用lxml

22. 序列化
- pickle协议
对于不可序列 化的对象，如 sockets、文件句柄、数据库连接等，也可以通过实现 pickle 协议来解决这 些巨献，主要是通过特殊方法 __getstate__() 和 __setstate__() （在对象类中实现这两个方法）来返回实例在被 pickle 时的状态。
- json
不支持datetime，可以：
```Python
import datetime
from time import mktime
try:
    import simplejson as json
except ImportError:
import json
class DateTimeEncoder(json.JSONEncoder):
    def default(self, obj):
# 为 JSONEncoder 进行扩展
        if isinstance(obj, datetime.datetime):
            return obj.strftime("%Y-%m-%d %H:%M:%S")
        elif isinstance(obj, date):
            return obj.strftime("%Y-%m-%d")
        return json.JSONEncoder.default(self, obj)
d = datetime.datetime.now()
print(json.dumps(d, cls=DateTimeEncoder)) # 使用 cls 指定编码器的名称
```

23. 使用traceback获取栈信息
traceback.print_exc()

24. 使用logging模块同时输出到console和文件
```python
console = logging.StreamHandler()
console.setLevel(logging.ERROR)
formatter = logging.Formatter("%(name)-12s: %(levelname)-8s %(message)s") console.setFormatter(formatter)
logging.getLogger('').addHandler(console)
```

Logging 只是线程安全的，不支持多进程写入同一个日志文件，因此对于多个进程，需要 配置不同的日志文件。
为了方便地找出问题所在，logging 的名字建议以模块或者 class 来命名。Logging 名称 遵循按 "." 划分的继承规则.

25. 使用threading模块编写多线程
thread 模块提供了多线程底层支持模块，以低级原始的方式来处理和控制线程，使用起来较 为复杂;而 threading 模块基于 thread 进行包装，将线程的操作对象化，在语言层面提供了 丰富的特性。

thread 模块不支持守护线程。thread 模块中主线程退出的时候，所有的子线程不论是否 还在工作，都会被强制结束，并且没有任何警告，也没有任何退出前的清理工作。
Python3中的thread变成了_thread。


26. 使用Queue使多线程更安全

Python 中的 Queue 模块提供了 3 种队列:
- Queue.Queue(maxsize) :先进先出，maxsize 为队列大小，其值为非正数的时候为无限循 环队列
- Queue.LifoQueue(maxsize) :后进先出，相当于栈 Queue.PriorityQueue(maxsize) :优先级队列

这 3 种队列支持以下方法:
- Queue.qsize() :返回近似的队列大小。之所以说是近似，当该值 > 0 的时候并不保证并 发执行的时候 get() 方法不被阻塞，同样，对于 put() 方法有效。
- Queue.empty() :队列为空的时候返回 True，否则返回 False
- Queue.full() :当设定了队列大小的情况下，如果队列满则返回 True，否则返回 False。
- Queue.put(item[, block[, timeout]]) :往队列中添加元素 item，block 设置为 False 的 时候，如果队列满则抛出 Full 异常。如果 block 设置为 True，timeout 为 None 的时候则 会一直等待直到有空位置，否则会根据 timeout 的设定超时后抛出 Full 异常。
- Queue.put_nowait(item) :等于 put(item, False).block 设置为 False 的时候，如果队 列空则抛出 Empty 异常。如果 block 设置为 True、timeout 为 None 的时候则会一直等 到有元素可用，否则会根据 timeout 的设定超时后抛出 Empty 异常。【个人:这里是不 是说反了?】
- Queue.get([block[, timeout]]) :从队列中删除元素并返回该元素的值 Queue.get_nowait() :等价于 get(False)
- Queue.task_done() :发送信号表明入列任务已经完成，经常在消费者线程中用到 Queue.join() :阻塞直至队列中所有的元素处理完毕。

```python
#多线程下载
import os
import Queue
import threading
import urllib2
class DownloadThread(threading.Thread):
    def __init__(self, queue):
        threading.Thread.__init__(self)
        self.queue = queue
    def run(self):
        while True:
            url = self.queue.get()
            # 从队列中取出一个 url 元素
            print(self.name + "begin download" + url + "...")
            self.download_file(url) # 进行文件下载 self.queue.task_done()
            # 下载完毕发送信号
            print(self.name + " download completed!!!")
    def download_file(self, url): # 下载文件 urlhandler = urllib2.urlopen(url)
        fname = os.path.basename(url) + ".html" with open(fname, "wb") as f: # 打开文件
            while True:
                chunk = urlhandler.read(1024)
                if not chunk:
                    break
                f.write(chunk)
if __name__ == "__main__":
    # 文件名称
    urls = ["https://www.createspace.com/3611970","http://wiki.python.org/moni.WebProgramming"]
    queue = Queue.Queue()
        # create a thread pool and give them a queue
    for i in range(5):
        t = DownloadThread(queue)
        t.setDaemon(True)
        t.start()
    # give the queue some data
    for url in urls:
        queue.put(url)
    # wait for the queue to finish
    queue.join()
```

27. 发布订阅设计模式
注意是先订阅后发布！！！这样回调才有意义啊~~~~
```python
from collections import defaultdict
route_table = defaultdict(list)
def sub(self, topic, callback):
    if callback in route_table[topic]:
        return
    route_table[topic].append(callback)
def pub(self, topic, *a, **kw):
    for func in route_table[topic]:
        func(*a, **kw)
```
python-message 提供了类装饰函数 observable() ，任何 class 只需要通过它装饰一下就拥 有了 sub/ubsub/pub/declare/retract 等方法，它们的使用方法跟全局函数是类似的。`pip install message`.

28. 用状态模式♣️代码
`pip install state`.
被 @stateful 修饰后的类的实例是带有 状态的，能有使用 curr() 查询当前状态，也可以使用 switch() 进行状态切换。

对于一个 @stateful 类而言，有一个默认 的状态(即其实例初始化后的第一个状态)，通过类定义的 default 属性标识，defalut 设置为 True 的类成为默认状态。

```python
from state import curr, switch, stateful, State, behavior
@stateful
class People(object):
    class Workday(State):
        default = True
        @behavior
        def day(self):
            print("work hard!")
    class Weekend(State):
        @behavior
        def day(self):
            print("play harder!")
people = People()
while True:
    for i in xrange(1, 8):
        if i == 6:
            switch(people, People.Weekend)
        if i == 1:
            switch(people, People.Workday)
        people.day()
```


29. 理解built-in objects
古典类(classic class)和新式类的区别：新式类继承自 object 类或者内建类型。我们不能简单地从 定义的形式上来判断一个类是新式类还是古典类(__metaclass__ 属性会影响到)，应当通 过元类的类型来确定类的类型:古典类的元类为 types.ClassType ，新式类的元类为 type 类。

30. __init__()不是构造方法
__init__() 并不是真正意义上的构造方法，__init__() 方法所做的工作是在类的对象创建 好之后进行变量的初始化。__new__() 方法才会真正创建实例，是类的构造方法。这两个方 法都是 object 类中默认的方法，继承自 object 的新式类，如果不覆盖这两个方法将会默认调 用 object 中对应的方法。
![](http://opkk27k9n.bkt.clouddn.com/17-7-11/73478474.jpg)

31. 理解名字查找机制
在一个 globals() 的表里可以看到全局变量，注意如果是在 Python shell 中执行
locals() ，也可以看到全局的变量。如果在一个函数里面定义这些变量，情况就会有所不
同。
依次搜索 4 个作用 域:局部作用域、嵌套作用域、全局作用域以及内置作用域。

Python3引入了nonlocal关键字，防止global的副作用。

32. self不是关键字
实例方法是作用于对象的，最简单的方式就是将对象本身传递到该方法中去，self 的存在 保证了 `A.__dict__['m'](a, 2) `使用和 `a.m(2)`一致。(a是A的实例)

33. 理解MRO与多继承
![](http://opkk27k9n.bkt.clouddn.com/17-7-11/56417261.jpg)

34. 区别 __getattr__() 和 __getattribute__()方法
需要注意的是 __getattribute__() 仅用于新式类。

35. 使用property
property(fget=None, fset=None, fdel=None, doc=None) -> property attribute

property是类。也可以作装饰器。
```python
class Some_Class(object):
    def __init__(self):
        self._somevalue = 0
    def get_value(self):
        return self._somevalue
    def set_value(self, value):
        self._somevalue = value
    def del_attr(self):
        del self._somevalue
    x = property(get_value, set_value, del_attr, "I am the ''x' property.")
# 'x' in dir(Some_Class()) 
# Some_Class().x = 0
```

36. 掌握metaclass
![](http://opkk27k9n.bkt.clouddn.com/17-7-11/33815799.jpg)

37. 使用操作符重载实现中缀语法
统计文件中每个单词出现的次数，然后按照次数从高到低对单词排序:
```python
from __future__ import print_function
from re import split
from pipe import *
with open("test_descriptor.py") as f:
    print(f.read()
          | Pipe(lambda x: split("/W+", x))
          | Pipe(lambda x:(i for i in x if i.strip()))
          | groupby(lambda x:x)
          | select(lambda x:(x[0], (x[1] | count)))
          | sort(key=lambda x: x[1], reverse=True)
)
```

38. 熟悉Python的迭代器协议
![](http://opkk27k9n.bkt.clouddn.com/17-7-11/48442372.jpg)

39. 熟悉Python的生成器
生成器还有两个很棒的用处，其中之一就是实现 with 语句的上下文管理协议，利用的是调用 生成器函数时函数体并不执行，当第一次调用 next() 方法时才开始执行，并执行到 yield 表 达式后中止，直到下一次调用 next() 方法这个特性;其二是实现协程，利用的是
send() 、 throw() 、 close() 等特性。

上下文管理器协议，其实就是要求类实现 __enter__() 和 __exit__() 方法，但是生成器对象并没有这两个方法，所以 contextlib 提供了 contextmanager 函数来适配这两种协议:
```python
from contextlib import contextmanager
@contextmanager
def tag(name):
    print("<{}>".format(name))
    yield
    print("</{}>".format(name))
with tag('h1'):
    print("foo")
```

40. 基于生成器的协程及greenlet
协程往往实现在语言的运行时库或虚拟机 中，操作系统对其存在一无所知，所以又被称为用户空间线程或绿色线程。又因为大部分协 程的实现是协作式而非抢占式的，需要用户自己去调度，所以通常无法利用多核，但用来执 行协作式多任务非常合适。

基于生产着消费者模型，比较抢占式多线程编程实现和协程编程实现。线程实现至少有两点硬伤:
- 对队列的操作需要有显式/隐式(使用线程安全的队列)的加锁操作。 
- 消费者线程还要通过 sleep 把 CPU 资源适时地“谦让”给生产者线程使用，其中的适时只 能静态地使用经验值。
  
而使用协程（虽然损失了利用多核CPU的能力）：
```
# 队列容器
q = new queue
# 生产者协程
loop
    while q is not full
        create some new items
        add the items to q
    yield to consume
# 消费者协程
loop
    while q is not empty
        remove some items from q
        use the items
    yield to produce
```
```python
def consumer():
    while True:
        line = yield
        print(line.upper())
def producter():
    with open("/var/log/apache2/error_log", "r") as f:
        for i, line in enumerate(f):
            yield line
            print("processed line {}".format(i))
c = consumer()
c.next()
for line in producter():
    c.send(line)
```
协程，每输出一行大写的文字后都有一行来自主程序的处理信息，不会像抢占式的多线程程 序那样“乱序”。Python2.X 版本的生成器无法实现所有的协程特性，是因为缺乏对协程之间复 杂关系的支持。比如一个 yield 协程依赖另一个 yield 协程，且需要由最外层往最内层进行传 值的时候，就没有解决办法。
这个问题直到 Python3.3 增加了 yield from 表达式以后才得以解决，通过 yield from ，外 层的生成器在接收到 send() 或 throw() 调用时，能够把实参直接传入内层生成器。

greenlet是一个C语言编写的程序库。greenlet 这个库里 最为关键的一个类型就是 PyGreenlet 对象，它是一个 C 结构体，每一个 PyGreenlet 都可以 看到一个调用栈，从它的入口函数开始，所有的代码都在这个调用栈上运行。它能够随时记 录代码运行现场，并随时中止，以及恢复。它跟 yield 所能够做到的相似，但更好的是它提供 从一个 PyGreenlet 切换到另一个 PyGreenlet 的机制。

协程虽然不能充分利用多核，但它跟异步 I/O 结合起来以后编写 I/O 密集型应用非常容易，能 够在同步的代码表面下实现异步的执行，其中的代表当属将 greenlet 与 libevent/libev 结合起 来的 gevent 程序库，它是 Python 网络编程库。最后，以 gevent 并发查询 DNS 的例子为 例，使用它进行并发查询 n 个域名，能够获得几乎 n 倍的性能提升:
```python
import gevent
from gevent import socket
urls = ["www.google.com", "www.example.com", "www.python.org"]
jobs = [gevent.spawn(socket.gethostbyname, url) for url in urls]
gevent.joinall(jobs, timeout=2)
print([job.value for job in jobs])
```

41. 理解GIL的局限性
Python 提供了其他方式可以绕过 GIL 的局限，比如使用多进程 multiprocess 模块或者采用 C 语言扩展的方式，以及通过 ctypes 和 C 动态库来充分利用物理内核的计算能力。
类 Process 是 multiprocess 中较为重要的一个类，用户创建进程，其构造函数如 下: Process([group[, target[, name[, args[, kwargs]]]]])
其中，参数 target 表示可调用对象;args 表示调用对象的位置参数元组;kwargs 表示调用对 象的字典;name 为进程的名称;group 一般设置为 None。该类提供的方法与属性基本上与 threading.Thread 一致，包括 is_alive()、join([timeout])、run()、start()、terminate()、 daemon(要通过 start() 设置)、exitcode、name、pid 等。
![](http://opkk27k9n.bkt.clouddn.com/17-7-11/30693040.jpg)

在进程通信的时候，如果是超过 2 个以上的线程，可以使 用 queue，但对于两个进程之间的通信而言 Pipe 性能更快。（multiprocessing.Pipe不支持进程安全）
```python
from multiprocessing import Process, Pipe, Queue
import time
def reader_pipe(pipe):
    output_p, input_p = pipe
    inout_p.close()
    while True:
        # 返回管道的两端
        try:
            msg = output_p.recv() # 从 pipe 中读取消息
        except EOFError:
            break
def writer_pipe(count, input_p):
    # 写消息到管道中
    for i in range(0, count):
        input_p.send(i)# 发送消息
def reader_queue(queue):
    # 利用队列来发送消息 
    while True:
        msg = queue.get()# 从队列中获取元素
        if msg == "DONE":
            break
def writer_queue(count, queue):
    for ii in range(0, count):
        # 放入消息队列中
        queue.put(ii)
    queue.put("DONE")

if __name__ == "__main__":
    print("testing for pipe:")
    for count in [10 ** 3, 10 ** 4, 10 ** 5]:
        output_p, input_p = Pipe()
        reader_p = Process(target=reader_pipe, args=((output_p, input_p),))
        # 启动进程
        reader_p.start()
        output_p.close()
        _start = time.time()
        write_pipe(count,input_p)   #写消息到管道中
        input_p.close() 
        reader_p.join() #等待进程处理完毕
        print("Sending {} numbers to Pipe() took {} seconds".format(count, (time.time(
) - _start)))

        print("testsing for queue:")
        for count in [10 ** 3, 10 ** 4, 10 ** 5]:
            queue = Queue() # 利用 queue 进行通信 r
            eader_p = Process(target=reader_queue, args=((queue),)) reader_p.daemon = True
            reader_p.start()
            _start = time.time()
            writer_queue(count, queue) # 写消息到 queue 中
            reader_p.join()
            print("Seding {} numbers to Queue() took {} seconds".format(count, (time.time(
) - _start)))
```
尽量避免资源共享。相比于线程，进程之间资源共享的开销较大，因此要尽量避免资源 共享。但如果不可避免，可以通过 multiprocessing.Value 和 multiprocessing.Array 或者 multiprocessing.sharedctpyes 来实现内存共享，也可以通过服务器进程管理器 Manager() 来实现数据和状态的共享。这两种方式各有优势，总体来说共享内存的方式更快，效率更高，但服务器进程管理器 Manager() 使用起来更为方便，并且支持本地和远 程内存共享。

注意平台之间的差异。由于 Linux 平台使用 fork() 来创建进程，因此父进程中所有的 资源，如数据结构、打开的文件或者数据库的连接都会在子进程中共享，而 Windows 平 台中父子进程相对独立，因此为了更好地保持平台的兼容性，最好能够将相关资源对象 作为子进程的构造函数的参数传递进去。`p = Process(target=child,args=(f,))#将资源对象只需欧唯你构造参数传入`

42. 循环引用造成的gc问题
```python
def main():
    collected = gc.collect()
    print("Garbage collector before running: collected {} objects.".format(collected)) 
    print("Creating reference cycles...")
    A = Leak()
    B = Leak()
    A.b = B
    B.a = A
    A = None
    B = None
    collected = gc.collect()
    print(gc.garbage)
    print("Garbage collector after running: collected {} objects".format(collected))
if __name__ == "__main__":
    import gc
    print(gc.isenabled())
    print(gc.get_threshold())
    ret = main()
    sys.exit(ret)
```

42. 单元测试框架 PyUnit/unittest/nose
nose更好。

43. pylint
使用 Pylint 分析代码，输出分为两部分:一部分为源代码分析结果，第二部分为统计报告。 报告部分主要是一些统计信息，总体来说有以下6 类:
- Statistics by type :检查的模块、函数、类等数量，以及它们中存在文档注释以及不 良命名的比例
- Raw metrics :代码、注释、文档、空行等占模块代码量的百分比统计
- Duplication :重复代码的统计百分比
- Messages by category :按照消息类别分类统计的信息以及和上一次运行结果的对比 Messages :具体的消息 ID 以及它们出现的次数
- Global evaluation :根据公式计算出的分数统计: 10.0 - ((float(5 * error + warning + refactor + convention) / statement) * 10)

44. 性能优化
工具
- Psyco
- Pypy
- cPython

cProfile定位性能瓶颈。` import cProfile;Profile.run("foo()")`。
foo()是调用的函数。
使用 memory_profiler 和 objgraph 剖析内 存使用。
![](http://opkk27k9n.bkt.clouddn.com/17-7-11/91019109.jpg)

循环的优化应遵循的原则是尽量减少循环过程中的计算量，多重循环的情形下尽量将内层的计算提到上一层。
```python
# 较慢
x = [10, 34, 56, 78]
def f(x):
    for i in range(len(x)):
        x[i] = math.sin(x[i])
return x
# 较快
def g(x):
    loc_sin = math.sin
    for i in range(len(x)):
        x[i] = loc_sin(x[i])
    return x

# 较慢
for i in range(len(v1)):
    for j in range(len(v2)):
        x = v1[i] + v2[j]
# 较快
for i in range(len(v1)):
    v1i = v1[i]
    for j in range(len(v2)):
        x = v1i + v2[j]
```

**如果 list 对象经常有元素数量的巨 变，应当考虑使用 deque。**
deque 就是双端队列，同时具备栈和队列的特性，能够提供在两端插入和删除时复杂度为 O(1) 的操作。相对于 list，它最大的优势在于内存管理方面。

对于序列容器，除了插入、删除、查找之外，还有一种很常见的需求是获取其中的极大值或 极小值元素，这时候，可以使用 heapq 模块。类似 bisect，heapq 也是维护列表的一组函 数，其中 heapify() 的作用是把一个序列容器转化为一个堆。
```shell
>> import heapq
>>> import random
>>> alist = [random.randint(0, 100) for i in range(10)]
>>> heapq.heapify(alist)
```
可以看到，转化为堆后，alist 的第一个元素 alist[0] 是整个列表中最小的元素，heapq 将 保证这一点，从而保证从列表中获取最小值元素的时间复杂度是 O(1)。

除了对容器的操作可能会出现性能问题外，容器中存储的元素也有很大的优化空间，在很多 业务中，容器存储的元素往往是同一类型的，比如都是整数，此时就可以用 array 优化程序性 能:
array 对象与 str 不同，它是可变对象，可以随意修改某一元素的值。
>>> import heapq
>>> import random
>>> alist = [random.randint(0, 100) for i in range(10)]
>>> heapq.heapify(alist)
>>> import array
>>> a = array.array("c", "i_am_a_string") # 'c'表示存储的每个元素都相当于 C 语言中的 char 类 型，占用内存大小为 1 字节。

![](http://opkk27k9n.bkt.clouddn.com/17-7-11/56082140.jpg)

45. 使用线程池提高效率
线程的生命周期分为 5 个状态:创建、就绪、运行、阻塞和终止。自线程创建到终 止，线程便不断在运行、就绪和阻塞这 3 个状态之间转换直至销毁。而真正占有 CPU 的只有 运行、创建和销毁这 3 个状态。一个线程的运行时间由此可以分为 3 部分:线程的启动时间 (Ts)、线程体的运行时间(Tr)以及线程的销毁时间(Td)。在多线程处理的情境中，如 果线程不能够被重用，就意味着每次创建都需要经过启动、销毁和运行这 3 个过程。这必然 会增加系统的相应时间，降低效率。而线程体的运行时间 Tr 不可控制，在这种情况下要提高 线程运行的效率，线程池便是一个解决方案。

46. 使用Cython编写扩展模块
Pyrex、Py2C 和 Cython 等。而从 Pyrex 发展而 来的 Cython 是其中的集大成者。
`cython arithmetic.py`生成.c文件，然后`gcc -shared -pthread -fPIC -fwrapv -02 -Wall -fno-strict-aliasing -I /usr/include/python2.7 -o arithmetic.so arithmetic.c`编译。

将生成的文件 arithmetic.so 复制到 Python 的 site_packages 目录下，或者将 pr.so 所在目 录的路径添加到 sys.path 中，就可以使用 C 扩展的模块了。

每一次都需要编译、等待有点麻烦，所以 Cython 很体贴地提供了无需显式编译的方案: pyximport。只要将原有的 Python 代码后缀名从 .py 改为 .pyx 即可:
>>> import pyximport
>>> pyximport.install()
>>> import arithmetic
从 __file__ 属性可以看出，这个 .pyx 文件已经被编译链接为共享库了，pyximport 的确方 便。