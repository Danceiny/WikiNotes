1. 人工智能

>学习概念的符号表示。作为搜索问题的机器学习。作为提高问题求解能力途径的学习。使
用先验的知识和训练数据一起引导学习。

2. 贝叶斯方法

>作为计算假设概率的基础的贝叶斯法则。朴素贝叶斯分类器。估计未观测到变量的值的算
法。

3. 计算复杂性理论

>不同学习任务中固有的复杂性的理论边界，以计算量、训练样例数量、出错数量等衡量。

4. 控制论

>为了优化预定目标，学习对各种处理过程进行控制，学习预测被控制的过程的下一个状态。

5. 信息论

>熵和信息内容的度量。学习的最小描述长度方法。编码假设时，它的最佳编码和与最佳训练序列的关系。

6. 哲学

>“奥坎姆的剃刀”（Occam’s razor）最简单的假设是最好的。从观察到的数据泛化的理由分析。

7. 心理学和神经生物学

>实践的幂定律（power law of practice），该定律指出对于很大范围内的学习问题，人们的反应速度随着实践次数的幂级提高。激发人工神经网络的学习模式的神经生物学研究。

8. 统计学

>在估计有限数据样本上的假设精度时出现的误差（例如偏差和方差）的刻画。置信区间，统计检验。